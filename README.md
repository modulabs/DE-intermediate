## 데이터 엔지니어링 중급

>  엔지니어링 업무의 가장 기본은 데이터를 수집하고, 가공 및 적재를 통해 데이터 서비스를 제공하는 일련의 과정이며, 이러한 파이프라인을 잘 구성하고 제공하는 것입니다. 특히 대용량 데이터를 처리하는 분산 시스템의 경우 레거시 시스템의 정보를 분산 저장소에 어떻게 저장할 수 있으며, 한 번 저장된 데이터를 정재 및 가공을 통해서 지표 혹은 2차 3차 가공 데이터를 추출하는 방법 그리고 다양한 데이터 제품을 개발하고 이러한 데이터를 다수의 사용자가 읽고 재가공할 수 있도록 저장 및 조회 시스템을 구성하는 것이 아주 중요합니다. 이러한 일련의 데이터 파이프라인 구성에 필요한 기본적인 하둡 에코시스템에 대해 이해하고 실습을 통해서 학습하는 것이 이번 과정의 목표입니다

* 저자
  * 기업 내외에서 발생하는 다양한 형태의 데이터를 수집, 변환 및 적재를 위한 다양한 기술을 연구하고 이러한 작업을 좀 더 자동화 할 수 있는 서비스와 플랫폼을 개발하는 업무를 하고 있습니다
* 소개
  * 
* 목적
  * 
* 대상
  * 
* 내용
  * [데이터 엔지니어링 기본](https://github.com/psyoblade/data-engineer-intermediate-training/tree/master/day1/README.md) : 
  * [아파치 스쿱](https://github.com/psyoblade/data-engineer-intermediate-training/tree/master/day2/README.md) : 
  * [아파치 스파크](https://github.com/psyoblade/data-engineer-intermediate-training/tree/master/day3/README.md) : 
  * [아파치 하이브](https://github.com/psyoblade/data-engineer-intermediate-training/tree/master/day4/README.md) : 
  * [지표 생성 프로젝트](https://github.com/psyoblade/data-engineer-intermediate-training/tree/master/day5/README.md) : 
* 맺음말
